Automatically generated by Mendeley Desktop 1.19.4
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Khan2020,
abstract = {Deep Convolutional Neural Network (CNN) is a special type of Neural Networks, which has shown exemplary performance on several competitions related to Computer Vision and Image Processing. Some of the exciting application areas of CNN include Image Classification and Segmentation, Object Detection, Video Processing, Natural Language Processing, and Speech Recognition. The powerful learning ability of deep CNN is primarily due to the use of multiple feature extraction stages that can automatically learn representations from the data. The availability of a large amount of data and improvement in the hardware technology has accelerated the research in CNNs, and recently interesting deep CNN architectures have been reported. Several inspiring ideas to bring advancements in CNNs have been explored, such as the use of different activation and loss functions, parameter optimization, regularization, and architectural innovations. However, the significant improvement in the representational capacity of the deep CNN is achieved through architectural innovations. Notably, the ideas of exploiting spatial and channel information, depth and width of architecture, and multi-path information processing have gained substantial attention. Similarly, the idea of using a block of layers as a structural unit is also gaining popularity. This survey thus focuses on the intrinsic taxonomy present in the recently reported deep CNN architectures and, consequently, classifies the recent innovations in CNN architectures into seven different categories. These seven categories are based on spatial exploitation, depth, multi-path, width, feature-map exploitation, channel boosting, and attention. Additionally, the elementary understanding of CNN components, current challenges, and applications of CNN are also provided.},
archivePrefix = {arXiv},
arxivId = {1901.06032},
author = {Khan, Asifullah and Sohail, Anabia and Zahoora, Umme and Qureshi, Aqsa Saeed},
doi = {10.1007/s10462-020-09825-6},
eprint = {1901.06032},
issn = {15737462},
journal = {Artificial Intelligence Review},
keywords = {Channel boosted CNN,Convolutional neural networks,Deep learning,Representational capacity,Residual learning,Taxonomy},
month = {jan},
number = {8},
pages = {5455--5516},
publisher = {Springer Science and Business Media B.V.},
title = {{A survey of the recent architectures of deep convolutional neural networks}},
url = {http://arxiv.org/abs/1901.06032 http://dx.doi.org/10.1007/s10462-020-09825-6},
volume = {53},
year = {2020}
}
@inproceedings{Toth2013,
abstract = {The introduction of deep neural networks to acoustic modelling has brought significant improvements in speech recognition accuracy. However, this technology has huge computational costs, even when the algorithms are implemented on graphic processors. Hence, finding the right training algorithm that offers the best performance with the lowest training time is now an active area of research. Here, we compare three methods; namely, the unsupervised pre-training algorithm of Hinton et al., a supervised pre-training method that constructs the network layer-by-layer, and deep rectifier networks, which differ from standard nets in their activation function. We find that the three methods can achieve a similar recognition performance, but have quite different training times. Overall, for the large vocabulary speech recognition task we study here, deep rectifier networks offer the best tradeoff between accuracy and training time. {\textcopyright} 2013 Springer-Verlag.},
author = {T{\'{o}}th, L{\'{a}}szl{\'{o}} and Gr{\'{o}}sz, Tam{\'{a}}s},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-642-40585-3_6},
file = {:C$\backslash$:/Users/Reid/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/T{\'{o}}th, Gr{\'{o}}sz - Unknown - A Comparison of Deep Neural Network Training Methods for Large Vocabulary Speech Recognition.pdf:pdf},
isbn = {9783642405846},
issn = {03029743},
keywords = {LVCSR,TIMIT,deep neural networks},
pages = {36--43},
title = {{A comparison of deep neural network training methods for large vocabulary speech recognition}},
volume = {8082 LNAI},
year = {2013}
}
@misc{Ambalina2020,
author = {Ambalina, Limarc},
title = {{10 Must-read Machine Learning Articles (March 2020) | by Limarc Ambalina | Towards Data Science}},
url = {https://towardsdatascience.com/10-must-read-machine-learning-articles-march-2020-80da9c380981},
urldate = {2021-01-21},
year = {2020}
}
@inproceedings{He2015,
abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers - 8× deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57{\%} error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28{\%} relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC {\&} COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.},
archivePrefix = {arXiv},
arxivId = {1512.03385},
author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
booktitle = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2016.90},
eprint = {1512.03385},
isbn = {9781467388504},
issn = {10636919},
month = {dec},
pages = {770--778},
publisher = {IEEE Computer Society},
title = {{Deep residual learning for image recognition}},
url = {http://arxiv.org/abs/1512.03385},
volume = {2016-Decem},
year = {2016}
}
@article{Cichy2016,
abstract = {The complex multi-stage architecture of cortical visual pathways provides the neural basis for efficient visual object recognition in humans. However, the stage-wise computations therein remain poorly understood. Here, we compared temporal (magnetoencephalography) and spatial (functional MRI) visual brain representations with representations in an artificial deep neural network (DNN) tuned to the statistics of real-world visual recognition. We showed that the DNN captured the stages of human visual processing in both time and space from early visual areas towards the dorsal and ventral streams. Further investigation of crucial DNN parameters revealed that while model architecture was important, training on real-world categorization was necessary to enforce spatio-temporal hierarchical relationships with the brain. Together our results provide an algorithmically informed view on the spatio-temporal dynamics of visual object recognition in the human visual brain.},
author = {Cichy, Radoslaw Martin and Khosla, Aditya and Pantazis, Dimitrios and Torralba, Antonio and Oliva, Aude},
doi = {10.1038/srep27755},
file = {:C$\backslash$:/Users/Reid/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Cichy et al. - 2016 - Comparison of deep neural networks to spatio-temporal cortical dynamics of human visual object recognition reveals.pdf:pdf},
issn = {20452322},
journal = {Scientific Reports},
keywords = {Object vision,Perception},
month = {jun},
number = {1},
pages = {1--13},
pmid = {27282108},
publisher = {Nature Publishing Group},
title = {{Comparison of deep neural networks to spatio-temporal cortical dynamics of human visual object recognition reveals hierarchical correspondence}},
url = {www.nature.com/scientificreports},
volume = {6},
year = {2016}
}
@article{Srivastava2015,
abstract = {Theoretical and empirical evidence indicates that the depth of neural networks is crucial for their success. However, training becomes more difficult as depth increases, and training of very deep networks remains an open problem. Here we introduce a new architecture designed to overcome this. Our so-called highway networks allow unimpeded information flow across many layers on information highways. They are inspired by Long Short-Term Memory recurrent networks and use adaptive gating units to regulate the information flow. Even with hundreds of layers, highway networks can be trained directly through simple gradient descent. This enables the study of extremely deep and efficient architectures.},
archivePrefix = {arXiv},
arxivId = {1507.06228},
author = {Srivastava, Rupesh Kumar and Greff, Klaus and Schmidhuber, J{\"{u}}rgen},
eprint = {1507.06228},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
month = {jul},
pages = {2377--2385},
title = {{Training Very Deep Networks}},
url = {http://arxiv.org/abs/1507.06228},
volume = {2015-Janua},
year = {2015}
}
@inproceedings{Simonyan2014,
abstract = {In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3 × 3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16–19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.},
archivePrefix = {arXiv},
arxivId = {1409.1556},
author = {Simonyan, Karen and Zisserman, Andrew},
booktitle = {3rd International Conference on Learning Representations, ICLR 2015 - Conference Track Proceedings},
eprint = {1409.1556},
month = {sep},
publisher = {International Conference on Learning Representations, ICLR},
title = {{Very deep convolutional networks for large-scale image recognition}},
url = {http://arxiv.org/abs/1409.1556},
year = {2015}
}
@misc{Fung2017,
author = {Fung, Vincent},
booktitle = {Towards data science},
title = {{An Overview of ResNet and its Variants | by Vincent Fung | Towards Data Science}},
url = {https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035},
urldate = {2021-01-21},
year = {2017}
}
