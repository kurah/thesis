Automatically generated by Mendeley Desktop 1.19.4
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Khan2020,
abstract = {Deep Convolutional Neural Network (CNN) is a special type of Neural Networks, which has shown exemplary performance on several competitions related to Computer Vision and Image Processing. Some of the exciting application areas of CNN include Image Classification and Segmentation, Object Detection, Video Processing, Natural Language Processing, and Speech Recognition. The powerful learning ability of deep CNN is primarily due to the use of multiple feature extraction stages that can automatically learn representations from the data. The availability of a large amount of data and improvement in the hardware technology has accelerated the research in CNNs, and recently interesting deep CNN architectures have been reported. Several inspiring ideas to bring advancements in CNNs have been explored, such as the use of different activation and loss functions, parameter optimization, regularization, and architectural innovations. However, the significant improvement in the representational capacity of the deep CNN is achieved through architectural innovations. Notably, the ideas of exploiting spatial and channel information, depth and width of architecture, and multi-path information processing have gained substantial attention. Similarly, the idea of using a block of layers as a structural unit is also gaining popularity. This survey thus focuses on the intrinsic taxonomy present in the recently reported deep CNN architectures and, consequently, classifies the recent innovations in CNN architectures into seven different categories. These seven categories are based on spatial exploitation, depth, multi-path, width, feature-map exploitation, channel boosting, and attention. Additionally, the elementary understanding of CNN components, current challenges, and applications of CNN are also provided.},
archivePrefix = {arXiv},
arxivId = {1901.06032},
author = {Khan, Asifullah and Sohail, Anabia and Zahoora, Umme and Qureshi, Aqsa Saeed},
doi = {10.1007/s10462-020-09825-6},
eprint = {1901.06032},
file = {:C$\backslash$:/Users/Reid/Documents/repositories/thesis/source{\_}papers/A Khan - A Sohail - U Zahoora et al -- A Survey of the Recent Architectures of Deep Convolutional Neural Networks.pdf:pdf},
issn = {15737462},
journal = {Artificial Intelligence Review},
keywords = {Channel boosted CNN,Convolutional neural networks,Deep learning,Representational capacity,Residual learning,Taxonomy},
month = {jan},
number = {8},
pages = {5455--5516},
publisher = {Springer Science and Business Media B.V.},
title = {{A Survey of the Recent Architectures of Deep Convolutional Neural Networks}},
url = {http://arxiv.org/abs/1901.06032 http://dx.doi.org/10.1007/s10462-020-09825-6},
volume = {53},
year = {2019}
}
@article{Beck2020,
abstract = {A lack of sufficient training data, both in terms of variety and quantity, is often the bottleneck in the development of machine learning (ML) applications in any domain. For agricultural applications, ML-based models designed to perform tasks such as autonomous plant classification will typically be coupled to just one or perhaps a few plant species. As a consequence, each crop-specific task is very likely to require its own specialized training data, and the question of how to serve this need for data now often overshadows the more routine exercise of actually training such models. To tackle this problem, we have developed an embedded robotic system to automatically generate and label large datasets of plant images for ML applications in agriculture. The system can image plants from virtually any angle, thereby ensuring a wide variety of data; and with an imaging rate of up to one image per second, it can produce lableled datasets on the scale of thousands to tens of thousands of images per day. As such, this system offers an important alternative to time- and cost-intensive methods of manual generation and labeling. Furthermore, the use of a uniform background made of blue keying fabric enables additional image processing techniques such as background replacement and image segementation. It also helps in the training process, essentially forcing the model to focus on the plant features and eliminating random correlations. To demonstrate the capabilities of our system, we generated a dataset of over 34,000 labeled images, with which we trained an ML-model to distinguish grasses from non-grasses in test data from a variety of sources. We now plan to generate much larger datasets of Canadian crop plants and weeds that will be made publicly available in the hope of further enabling ML applications in the agriculture sector.},
author = {Beck, Michael A. and Liu, Chen-Yi and Bidinosti, Christopher P. and Henry, Christopher J. and Godee, Cara M. and Ajmani, Manisha},
doi = {10.1371/journal.pone.0243923},
editor = {Gwak, Jeonghwan},
file = {:C$\backslash$:/Users/Reid/Documents/repositories/thesis/source{\_}papers/An Embedded System for the AUtomated Generation of Labeled Plant Images to Enable Machine Laerning Applications in Agriculture.pdf:pdf},
isbn = {1111111111},
issn = {1932-6203},
journal = {PLOS ONE},
month = {dec},
number = {12},
pages = {e0243923},
pmid = {33332382},
title = {{An embedded system for the automated generation of labeled plant images to enable machine learning applications in agriculture}},
url = {http://dx.doi.org/10.1371/journal.pone.0243923 https://dx.plos.org/10.1371/journal.pone.0243923},
volume = {15},
year = {2020}
}
