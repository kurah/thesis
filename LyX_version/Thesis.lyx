#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Thesis: Precision Agriculture Pipeline and Dataset Research Questions
\end_layout

\begin_layout Author
Reid C.
 S.
 Lowdon
\end_layout

\begin_layout Date
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
today
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage pagebreak
\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset toc
LatexCommand tableofcontents

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage pagebreak
\end_inset


\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Standard
In deep learning models are trained using labelled datasets on the order
 of hundreds of thousands of images; it is believed that the cleaner and
 larger the dataset the better it will be for training purposes.
 We built a system that will allow us to build our own datasets and thus
 we have full control over what the datasets are comprised of.
 This puts our group in a unique position as we can manipulate at the dataset
 level.
\end_layout

\begin_layout Section
Literature Review
\end_layout

\begin_layout Itemize
Literature review about:
\end_layout

\begin_deeper
\begin_layout Itemize
When do diminishing returns start to appear in terms of data quantity
\end_layout

\begin_layout Itemize
Where is the tipping point for 
\begin_inset Quotes eld
\end_inset

bad data
\begin_inset Quotes erd
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
\begin_inset Quotes eld
\end_inset

The Effect of Dirty Data on Deep Learning Systems
\begin_inset Quotes erd
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
https://thehive.ai/engineering/effect-of-dirty-data-on-deep-learning
\end_layout

\end_deeper
\end_deeper
\end_deeper
\begin_layout Subsection
Impacts of Dirty Data
\end_layout

\begin_layout Standard
Ensuring a data set is clean is the first step in utilizing a data set for
 training and is a very important first step to ensuring your models produce
 the results you are anticipating.
 From my research, I founnd it very difficult to find documents detailing
 research on the effects of dirty data on the accuracy of a neural network
 model.
 Thus, in this thesis I have conducted experiments to compare the effects
 of a dirty data set on several deep neural network architectures.
\end_layout

\begin_layout Standard
It is quite intuitive to think that if a data set contained dirty data,
 that data set would cause a model to have lower accuracy than a data set
 that does not contain dirty data.
\end_layout

\begin_layout Section
Deep Neural Network Training Pipeline
\end_layout

\begin_layout Standard
The first step was to create a deep neural network training pipeline which
 would be used to maximize my efficiency in terms of training deep neural
 network models and keeping all necessary data from each training run.
 This pipeline must be robust enough so that I can setup several consecutive
 training runs without having to build each piece manually every time.
 This includes querying a dataset using SQL from the main database, building
 that labeled dataset into an appropriate format for a given deep neural
 network architecture, load the dataset into the network, and execute the
 training function for a given number of epochs.
\end_layout

\begin_layout Subsection
Gantry System
\end_layout

\begin_layout Standard
Details regarding the gantry system maybe (not sure because Michael did
 this part, not me)
\end_layout

\begin_layout Subsection
Camera
\end_layout

\begin_layout Standard
Details regarding the camera system maybe (again, Michael did this part
 not me)
\end_layout

\begin_layout Subsection
Database
\end_layout

\begin_layout Standard
I chose to use Microsoft SQL Server 2017 primarily because it allowed me
 to use the FILESTREAM data type.
\end_layout

\begin_layout Subsubsection
FILESTREAM
\end_layout

\begin_layout Subsection
Dataset Export Utility
\end_layout

\begin_layout Standard
Details regarding the export utility that I created
\end_layout

\begin_layout Subsection
HDF5 Files
\end_layout

\begin_layout Standard
Details regarding why I decided to use hdf5 files for creating datasets
\end_layout

\begin_layout Subsection
Loading Data Into Models
\end_layout

\begin_layout Standard
How I load the datasets into the neural network models for training
\end_layout

\begin_layout Subsection
Training Models
\end_layout

\begin_layout Standard
How the training process works
\end_layout

\begin_layout Subsection
Executing the Models (NVIDIA Jetson Nano)
\end_layout

\begin_layout Standard
Packaging and using the trained models on an NVIDIA Jetson Nano
\end_layout

\begin_layout Standard
This pipeline is designed as an end to end pipeline and it covers the following
 main points:
\end_layout

\begin_layout Itemize
Images are taken by a GoPro attached to an XYZ gantry system
\end_layout

\begin_layout Itemize
These images are sent to our storage server
\end_layout

\begin_layout Itemize
The images are then inserted into the database along with any relevant metadata
\end_layout

\begin_layout Itemize
There is a utility to query out a subset of the dataset
\end_layout

\begin_layout Itemize
This subset is then used to train a deep neural network for inference
\end_layout

\begin_layout Itemize
The trained model is saved to disk after completion
\end_layout

\begin_layout Itemize
The trained model is then used for inference examples
\end_layout

\begin_layout Section
Methodology
\end_layout

\begin_layout Itemize
Trained several models on our dataset to get a baseline of accuracy
\end_layout

\begin_layout Itemize
Need to add 
\begin_inset Quotes eld
\end_inset

noise
\begin_inset Quotes erd
\end_inset

 into our dataset in specific amounts in order to see at what point do I
 start to notice a significant decline in accuracy
\end_layout

\begin_deeper
\begin_layout Itemize
Make sure to do this in percentages, as in 1% of the total dataset, then
 2%, then 3%, etc
\end_layout

\begin_deeper
\begin_layout Itemize
Setup a script to iterate through this training, have a folder containing
 up to 100% of the original dataset, throw in x% of images of bad data
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
Need to set up an experiment where I train models using certain percentages
 of the main dataset 
\end_layout

\begin_deeper
\begin_layout Itemize
I'm not sure that we have enough data yet for this to be tested properly
\end_layout

\begin_layout Itemize
This could potentially be done with another existing data set, it does not
 have to be ours
\end_layout

\end_deeper
\begin_layout Section
Results
\end_layout

\begin_layout Standard
The results of the aforementioned experiments will go here
\end_layout

\begin_layout Section
Discussion
\end_layout

\begin_layout Standard
A discussion of the results will go here
\end_layout

\begin_layout Section
Conclusion
\end_layout

\begin_layout Standard
A concluding paragraph or few will go here
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "key-1"

\end_inset


\end_layout

\end_body
\end_document
