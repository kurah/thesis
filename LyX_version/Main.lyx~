#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Precision Agriculture Pipeline and Dataset Research Questions
\end_layout

\begin_layout Author
Reid Lowdon
\end_layout

\begin_layout Date
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
today
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage pagebreak
\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset toc
LatexCommand tableofcontents

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage pagebreak
\end_inset


\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Standard
In deep learning models are trained using labelled datasets on the order
 of hundreds of thousands of images; it is believed that the cleaner and
 larger the dataset the better it will be for training purposes.
 We built a system that will allow us to build our own datasets and thus
 we have full control over what the datasets are comprised of.
 This puts our group in a unique position as we can manipulate at the dataset
 level; if we find that certain angles are better than others we can adjust
 for that, if we find that plants generally look the same at the beginning
 of their life cycle and it turns out that weighting the image quantity
 to have more at the beginning of the life cycle and less towards the end
 may be useful as well.
\end_layout

\begin_layout Section
Study Area
\end_layout

\begin_layout Standard
Study area details will go here
\end_layout

\begin_layout Section
Literature Review
\end_layout

\begin_layout Itemize
Literature review about:
\end_layout

\begin_deeper
\begin_layout Itemize
When do diminishing returns start to appear in terms of data quantity
\end_layout

\begin_layout Itemize
Where is the tipping point for 
\begin_inset Quotes eld
\end_inset

bad data
\begin_inset Quotes erd
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
\begin_inset Quotes eld
\end_inset

The Effect of Dirty Data on Deep Learning Systems
\begin_inset Quotes erd
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
https://thehive.ai/engineering/effect-of-dirty-data-on-deep-learning
\end_layout

\end_deeper
\end_deeper
\end_deeper
\begin_layout Section
Deep Neural Network Training Pipeline
\end_layout

\begin_layout Standard
The first step for me was to create a deep neural network training pipeline
 which would be used to maximize my efficiency in terms of training deep
 neural network models and keeping all necessary data from each training
 run.
\end_layout

\begin_layout Section
Methodology
\end_layout

\begin_layout Itemize
Trained several models on our dataset to get a baseline of accuracy
\end_layout

\begin_layout Itemize
Need to add 
\begin_inset Quotes eld
\end_inset

noise
\begin_inset Quotes erd
\end_inset

 into our dataset in specific amounts in order to see at what point do I
 start to notice a significant decline in accuracy
\end_layout

\begin_deeper
\begin_layout Itemize
Make sure to do this in percentages, as in 1% of the total dataset, then
 2%, then 3%, etc
\end_layout

\begin_deeper
\begin_layout Itemize
Setup a script to iterate through this training, have a folder containing
 up to 100% of the original dataset, throw in x% of images of bad data
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
Need to set up an experiment where I train models using certain percentages
 of the main dataset 
\end_layout

\begin_deeper
\begin_layout Itemize
I'm not sure that we have enough data yet for this to be tested properly
\end_layout

\begin_layout Itemize
This could potentially be done with another existing data set, it does not
 have to be ours
\end_layout

\end_deeper
\begin_layout Section
Results
\end_layout

\begin_layout Standard
The results of the aforementioned experiments will go here
\end_layout

\begin_layout Section
Discussion
\end_layout

\begin_layout Standard
A discussion of the results will go here
\end_layout

\begin_layout Section
Conclusion
\end_layout

\begin_layout Standard
A concluding paragraph or few will go here
\end_layout

\end_body
\end_document
